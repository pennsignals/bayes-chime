{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the normal approximations module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module explains how to approximate existing priors and posteriors with normal distributions and how to propagate errors.\n",
    "It compares the propagation of errors to existing data.\n",
    "For this reason, you first must generate a fit as specified in the (original) readme.\n",
    "The fits here have been computed for the Downtown area.\n",
    "\n",
    "Make sure you have installed the module and dependencies before you run this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, path\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from pandas import read_csv, read_json, DataFrame, Series, date_range, concat\n",
    "\n",
    "from gvar import gvar\n",
    "from gvar import mean as gv_mean\n",
    "from gvar import sdev as gv_sdev\n",
    "from gvar.dataset import avg_data\n",
    "\n",
    "from lsqfit import nonlinear_fit\n",
    "\n",
    "from seaborn import FacetGrid, distplot, despine\n",
    "from matplotlib.pylab import show as show_plot\n",
    "from matplotlib.pylab import subplots\n",
    "\n",
    "from bayes_chime.normal.models import SEIRModel\n",
    "from bayes_chime.normal import models as m\n",
    "from bayes_chime.normal.utilities import one_minus_logistic_fcn\n",
    "from bayes_chime.normal.fitting import fit_norm_to_prior_df, fit_norm_dist_to_ens\n",
    "from bayes_chime.normal.plotting import (\n",
    "    plot_prior_fit,\n",
    "    plot_band,\n",
    "    plot_gvar,\n",
    "    plot_posterior_fit,\n",
    "    plot_gv_dist,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update the RUN directory to load in your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = path.dirname(getcwd())\n",
    "RUN = \"2020_04_22_09_07_17\"\n",
    "\n",
    "OUTPUT = path.join(ROOT, \"output\", RUN)\n",
    "DATA = path.join(OUTPUT, \"parameters\")\n",
    "\n",
    "if not path.exists(DATA):\n",
    "    raise KeyError(\n",
    "        \"You have to point to an existing run directory to run this notebook.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DF = (\n",
    "    read_csv(path.join(DATA, \"census_ts.csv\"), parse_dates=[\"date\"])\n",
    "    .dropna(how=\"all\", axis=1)\n",
    "    .fillna(0)\n",
    "    .set_index(\"date\")\n",
    "    .astype(int)\n",
    ")\n",
    "DATA_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, priors are loaded in from file. Because the prior distributions are known (but not normal), they are approximated by normal distributions for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIOR_DF = read_csv(path.join(DATA, f\"params.csv\"))\n",
    "PRIOR_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PRIORS = fit_norm_to_prior_df(PRIOR_DF.query(\"distribution != 'constant'\"))\n",
    "META_PARS = fit_norm_to_prior_df(PRIOR_DF.query(\"distribution == 'constant'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = FacetGrid(\n",
    "    PRIOR_DF.query(\"distribution != 'constant'\"),\n",
    "    col=\"param\",\n",
    "    col_wrap=5,\n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    ")\n",
    "g.map_dataframe(plot_prior_fit)\n",
    "show_plot(g)\n",
    "DataFrame(data=PRIORS, index=[\"val\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, posterior distributions are fitted using normal distributions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below which reads in json may take a while. Maybe exporting to `HDF5` might be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTERIOR_DF = read_json(\n",
    "    path.join(OUTPUT, \"output\", \"chains.json.bz2\"), orient=\"records\", lines=True\n",
    ")\n",
    "drop_cols = [\n",
    "    col for col in POSTERIOR_DF.columns if col not in PRIORS and col != \"offset\"\n",
    "]\n",
    "POSTERIOR_DF = POSTERIOR_DF.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below fit removes outliers to stabilize the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = PRIORS.keys()\n",
    "POSTERIORS = avg_data(POSTERIOR_DF.T.loc[keys].T.values, median=True, spread=True)\n",
    "POSTERIORS = {key: val for key, val in zip(keys, POSTERIORS)}\n",
    "\n",
    "stacked = (\n",
    "    POSTERIOR_DF.T.loc[PRIORS.keys()]\n",
    "    .T.stack()\n",
    "    .reset_index()\n",
    "    .drop(columns=[\"level_0\"])\n",
    "    .rename(columns={\"level_1\": \"param\", 0: \"x\"})\n",
    ")\n",
    "g = FacetGrid(stacked, col=\"param\", col_wrap=5, sharex=False, sharey=False,)\n",
    "\n",
    "plot_dist = lambda **kwargs: distplot(\n",
    "    a=kwargs[\"data\"].x.values, kde=False, hist_kws={\"density\": True}\n",
    ")\n",
    "\n",
    "g.map_dataframe(plot_dist)\n",
    "\n",
    "for ax, gv in zip(g.axes, POSTERIORS.values()):\n",
    "    plot_gv_dist(gv, ax=ax, color=\"black\")\n",
    "\n",
    "show_plot(g)\n",
    "DataFrame(data=[POSTERIORS], index=[\"val\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagate normal posteriors to SEIR and compare to original prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes the fitted posterior distributions as input and propagates the parameter uncertainties through the SEIR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_DF = read_csv(\n",
    "    path.join(OUTPUT, \"output\", \"forecast.csv\"), parse_dates=[\"date\"]\n",
    ").set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the model is initialized.\n",
    "To eventually run the simulation, the following parameters must be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seir = SEIRModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model_parameters` must be provided before running a simulation.\n",
    "The `optional_parameters` are pre and post-processing parameters which simplify the interface.\n",
    "For example, if you specify `recovery_days`, this is used to compute `gamma`.\n",
    "\n",
    "On the other hand, `hospitalization_probability` and `market_share` will add hospitalization information to the simulation in the post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_infections = (\n",
    "    META_PARS[\"n_hosp\"] / META_PARS[\"mkt_share\"] / POSTERIORS[\"hosp_prop\"]\n",
    ")\n",
    "\n",
    "## Fixed paramters (no distributions)\n",
    "XX = {\n",
    "    \"dates\": FORECAST_DF.index,\n",
    "    \"market_share\": META_PARS[\"mkt_share\"],\n",
    "    \"initial_susceptible\": META_PARS[\"region_pop\"],\n",
    "    \"initial_infected\": 0,\n",
    "    \"initial_recovered\": 0,\n",
    "    \"initial_hospital\": 0,\n",
    "    \"initial_icu\": 0,\n",
    "    \"initial_vent\": 0,\n",
    "}\n",
    "## Variable parameters (distributions)\n",
    "PP = {\n",
    "    \"initial_exposed\": total_infections,\n",
    "    \"incubation_days\": POSTERIORS[\"incubation_days\"],\n",
    "    \"beta\": POSTERIORS[\"beta\"],\n",
    "    \"recovery_days\": POSTERIORS[\"recovery_days\"],\n",
    "    \"nu\": POSTERIORS[\"nu\"],\n",
    "    \"hospital_probability\": POSTERIORS[\"hosp_prop\"],\n",
    "    \"hospital_length_of_stay\": POSTERIORS[\"hosp_LOS\"],\n",
    "    \"icu_probability\": POSTERIORS[\"ICU_prop\"],\n",
    "    \"icu_length_of_stay\": POSTERIORS[\"ICU_LOS\"],\n",
    "    \"vent_probability\": POSTERIORS[\"vent_prop\"],\n",
    "    \"vent_length_of_stay\": POSTERIORS[\"vent_LOS\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to make parameters time-dependent. This is done by providing a `update_parameters` method. The arguments of this method are the simulation date and initial parameters (combined `XX` and `PP`). This method should return the updated parameters.\n",
    "In the below example, a social distancing measure is implemented using a logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(ddate, **kwargs):\n",
    "    xx = (ddate - kwargs[\"dates\"][0]).days\n",
    "    ppars = kwargs.copy()\n",
    "    ppars[\"beta\"] = kwargs[\"beta\"] * one_minus_logistic_fcn(\n",
    "        xx, L=kwargs[\"L\"], k=kwargs[\"k\"], x0=kwargs[\"x0\"],\n",
    "    )\n",
    "    return ppars\n",
    "\n",
    "\n",
    "OFFSET = POSTERIOR_DF.offset.mean()\n",
    "\n",
    "PP[\"L\"] = POSTERIORS[\"logistic_L\"]\n",
    "PP[\"x0\"] = POSTERIORS[\"logistic_x0\"] + OFFSET\n",
    "PP[\"k\"] = POSTERIORS[\"logistic_k\"]\n",
    "\n",
    "seir.update_parameters = update_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "seir.propagate_uncertainties(XX, PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCAST_DF_NORMAL = seir.propagate_uncertainties(XX, PP)\n",
    "FORCAST_DF_NORMAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = subplots(ncols=2, nrows=2, figsize=(12, 9))\n",
    "\n",
    "gv_kws = dict(color=\"black\", zorder=10, lw=3, z_factor=0.674)\n",
    "gv_line_kws = {\"ls\": \"--\", \"label\": \"Normal posteriors\"}\n",
    "gv_fill_kws = {\"alpha\": 0.2}\n",
    "\n",
    "fill_kws = {\"alpha\": 0.3, \"edgecolor\": \"k\", \"lw\": 2}\n",
    "line_kws = {\"ls\": \"-\", \"label\": \"General posteriors\", \"lw\": 2}\n",
    "\n",
    "t_range_shifted = FORECAST_DF.index - timedelta(days=OFFSET)\n",
    "\n",
    "# Census hospital\n",
    "ax = axs[0, 0]\n",
    "ax.set_ylabel(f\"COVID-19 Hospital Census\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True)\n",
    "\n",
    "## General posteriors\n",
    "plot_band(\n",
    "    x=FORECAST_DF.index,\n",
    "    y1=FORECAST_DF[\"Hospitalized Census 25%\"],\n",
    "    ym=FORECAST_DF[\"Hospitalized Census Median\"],\n",
    "    y2=FORECAST_DF[\"Hospitalized Census 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "## Normal posteriors\n",
    "plot_gvar(\n",
    "    x=t_range_shifted,\n",
    "    y=FORCAST_DF_NORMAL[\"hospital_census\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "# Census vent\n",
    "ax = axs[0, 1]\n",
    "ax.set_ylabel(f\"COVID-19 Vent Census\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True)\n",
    "\n",
    "## General posteriors\n",
    "plot_band(\n",
    "    x=FORECAST_DF.index,\n",
    "    y1=FORECAST_DF[\"Vent Census 25%\"],\n",
    "    ym=FORECAST_DF[\"Vent Census Median\"],\n",
    "    y2=FORECAST_DF[\"Vent Census 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "## Normal posteriors\n",
    "plot_gvar(\n",
    "    x=t_range_shifted,\n",
    "    y=FORCAST_DF_NORMAL[\"vent_census\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "\n",
    "\n",
    "# Admits hosp\n",
    "ax = axs[1, 0]\n",
    "ax.set_ylabel(f\"COVID-19 Hospital Admits\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True)\n",
    "\n",
    "## General posteriors\n",
    "plot_band(\n",
    "    x=FORECAST_DF.index,\n",
    "    y1=FORECAST_DF[\"Hospitalized Admits 25%\"],\n",
    "    ym=FORECAST_DF[\"Hospitalized Admits Median\"],\n",
    "    y2=FORECAST_DF[\"Hospitalized Admits 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "\n",
    "## Normal posteriors\n",
    "plot_gvar(\n",
    "    x=t_range_shifted,\n",
    "    y=FORCAST_DF_NORMAL[\"hospital_admits\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "\n",
    "# Admits vent\n",
    "ax = axs[1, 1]\n",
    "ax.set_ylabel(f\"COVID-19 Vent Admits\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True)\n",
    "\n",
    "## General posteriors\n",
    "plot_band(\n",
    "    x=FORECAST_DF.index,\n",
    "    y1=FORECAST_DF[\"Vent Admits 25%\"],\n",
    "    ym=FORECAST_DF[\"Vent Admits Median\"],\n",
    "    y2=FORECAST_DF[\"Vent Admits 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "\n",
    "## Normal posteriors\n",
    "plot_gvar(\n",
    "    x=t_range_shifted,\n",
    "    y=FORCAST_DF_NORMAL[\"vent_admits\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "\n",
    "\n",
    "fig.suptitle(\n",
    "    \"General vs normal posteriors @ 50% C.I.\", y=1.02, fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "fig.autofmt_xdate()\n",
    "fig.tight_layout()\n",
    "\n",
    "despine()\n",
    "show_plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the size of the census uncertainties differs by a few standard deviations while the mean agrees. This is interesting as they are computed using admission data (which agrees) and use the same function (see `bayes_chime/normal/models/sir.py` line 70). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute normal posteriors given normal priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, original priors are approximated by normal distributions and `lsqfit` is used to compute posteriors.\n",
    "\n",
    "To account for the offset, the data is extended with zeros before the first date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_range = date_range(\n",
    "    DATA_DF.index[0] - timedelta(int(OFFSET)), freq=\"D\", periods=OFFSET\n",
    ")\n",
    "tmp = DataFrame(index=extended_range, columns=DATA_DF.columns).fillna(0)\n",
    "extended_data = concat([tmp, DATA_DF])\n",
    "extended_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as above with the difference that now the priors are used instead of the posteriors and the date range is set by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_infections = META_PARS[\"n_hosp\"] / META_PARS[\"mkt_share\"] / PRIORS[\"hosp_prop\"]\n",
    "\n",
    "## Fixed paramters (no distributions)\n",
    "xx = {\n",
    "    \"dates\": extended_data.index,\n",
    "    \"market_share\": META_PARS[\"mkt_share\"],\n",
    "    \"initial_susceptible\": META_PARS[\"region_pop\"],\n",
    "    \"initial_infected\": 0,\n",
    "    \"initial_recovered\": 0,\n",
    "    \"initial_infected\": 0,\n",
    "    \"initial_recovered\": 0,\n",
    "    \"initial_icu\": 0,\n",
    "    \"initial_vent\": 0,\n",
    "    \"initial_hospital\": META_PARS[\"n_hosp\"] / META_PARS[\"mkt_share\"],\n",
    "}\n",
    "## Variable parameters (distributions)\n",
    "pp = {\n",
    "    \"initial_exposed\": total_infections,\n",
    "    \"incubation_days\": PRIORS[\"incubation_days\"],\n",
    "    \"beta\": PRIORS[\"beta\"],\n",
    "    \"recovery_days\": PRIORS[\"recovery_days\"],\n",
    "    \"nu\": PRIORS[\"nu\"],\n",
    "    \"hospital_probability\": PRIORS[\"hosp_prop\"],\n",
    "    \"hospital_length_of_stay\": PRIORS[\"hosp_LOS\"],\n",
    "    \"icu_probability\": PRIORS[\"ICU_prop\"],\n",
    "    \"icu_length_of_stay\": PRIORS[\"ICU_LOS\"],\n",
    "    \"vent_probability\": PRIORS[\"vent_prop\"],\n",
    "    \"vent_length_of_stay\": PRIORS[\"vent_LOS\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp[\"L\"] = PRIORS[\"logistic_L\"]\n",
    "pp[\"x0\"] = PRIORS[\"logistic_x0\"] + OFFSET\n",
    "pp[\"k\"] = PRIORS[\"logistic_k\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One has to specify the time range and data (columns) to fit. For now, this only fits the hospitalized census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seir.fit_start_date = \"2020-03-06\"\n",
    "seir.fit_columns = [\"hospital_census\", \"vent_census\"]\n",
    "seir.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, one needs to know the uncertainty of the data.\n",
    "Since I have no experience with how reliable this data is (one also must account for temporal fluctuations), I estimate the uncertainty to be 10% of the mean plus an additional 10 patients to not emphasize early points too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = gvar(\n",
    "    [DATA_DF.hosp.values, DATA_DF.vent.values],\n",
    "    [DATA_DF.hosp.values * 0.1 + 10, DATA_DF.vent.values * 0.1 + 2,],\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below method checks if the function call does not raise any problems (e.g., too few prior parameters or data is of the wrong shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seir.check_call(xx, yy, pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs the fit and computes posteriors (stored in `fit.p`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit = nonlinear_fit(data=(xx, yy), prior=pp, fcn=seir.fit_fcn, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nonlinear_fit(data=(xx, yy), prior=pp, fcn=seir.fit_fcn, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prediction = xx.copy()\n",
    "tf = FORECAST_DF.iloc[:100]\n",
    "x_prediction[\"dates\"] = tf.index\n",
    "df = seir.propagate_uncertainties(x_prediction, fit.p)\n",
    "df.index -= timedelta(days=OFFSET)\n",
    "\n",
    "fig, axs = subplots(ncols=2, nrows=2, figsize=(12, 9), sharex=False)\n",
    "\n",
    "gv_kws = dict(color=\"black\", zorder=10, lw=3, z_factor=0.674)\n",
    "gv_line_kws = {\"ls\": \"--\", \"label\": \"New normal fit\"}\n",
    "gv_fill_kws = {\"alpha\": 0.2}\n",
    "\n",
    "fill_kws = {\"alpha\": 0.3, \"edgecolor\": \"k\", \"lw\": 2}\n",
    "line_kws = {\"ls\": \"-\", \"label\": \"Original fit\", \"lw\": 2}\n",
    "\n",
    "\n",
    "# Census hospitalized\n",
    "ax = axs[0, 0]\n",
    "ax.set_ylabel(f\"COVID-19 Hospital Census\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True)\n",
    "\n",
    "## Fit hospitalized\n",
    "plot_gvar(\n",
    "    x=df.index,\n",
    "    y=df[\"hospital_census\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "\n",
    "## Original hospitalized\n",
    "ax.set_ylabel(f\"COVID-19 Hospital Census\", fontsize=12, fontweight=\"bold\")\n",
    "plot_band(\n",
    "    x=tf.index,\n",
    "    y1=tf[\"Hospitalized Census 25%\"],\n",
    "    ym=tf[\"Hospitalized Census Median\"],\n",
    "    y2=tf[\"Hospitalized Census 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "\n",
    "## Data hospitalized\n",
    "plot_gvar(\n",
    "    x=DATA_DF.index,\n",
    "    y=yy.T[0],\n",
    "    ax=ax,\n",
    "    z_factor=0.674,\n",
    "    color=\"red\",\n",
    "    line_kws={**line_kws, \"label\": \"Data\"},\n",
    "    fill_kws={**fill_kws, \"alpha\": 0.5, \"zorder\": 5},\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Admits hospitalized\n",
    "ax = axs[1, 0]\n",
    "ax.set_ylabel(f\"COVID-19 Hospital Admits\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "## Prediction hospitalized\n",
    "plot_gvar(\n",
    "    x=df.index,\n",
    "    y=df[\"hospital_admits\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "## Original hospitalized\n",
    "plot_band(\n",
    "    x=tf.index,\n",
    "    y1=tf[\"Hospitalized Admits 25%\"],\n",
    "    ym=tf[\"Hospitalized Admits Median\"],\n",
    "    y2=tf[\"Hospitalized Admits 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "\n",
    "# Census vent\n",
    "ax = axs[0, 1]\n",
    "ax.set_ylabel(f\"COVID-19 Vent Census\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True)\n",
    "\n",
    "## Fit vent\n",
    "plot_gvar(\n",
    "    x=df.index,\n",
    "    y=df[\"vent_census\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "\n",
    "## Original vent\n",
    "plot_band(\n",
    "    x=tf.index,\n",
    "    y1=tf[\"Vent Census 25%\"],\n",
    "    ym=tf[\"Vent Census Median\"],\n",
    "    y2=tf[\"Vent Census 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "\n",
    "## Data vent\n",
    "plot_gvar(\n",
    "    x=DATA_DF.index,\n",
    "    y=yy.T[1],\n",
    "    ax=ax,\n",
    "    z_factor=0.674,\n",
    "    color=\"red\",\n",
    "    line_kws={**line_kws, \"label\": \"Data\"},\n",
    "    fill_kws={**fill_kws, \"alpha\": 0.5, \"zorder\": 5},\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# Admits vent\n",
    "ax = axs[1, 1]\n",
    "ax.set_ylabel(f\"COVID-19 Vent Admits\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "## Prediction vent\n",
    "plot_gvar(\n",
    "    x=df.index,\n",
    "    y=df[\"vent_admits\"].values,\n",
    "    ax=ax,\n",
    "    **gv_kws,\n",
    "    line_kws=gv_line_kws,\n",
    "    fill_kws=gv_fill_kws,\n",
    ")\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "## Original hospitalized\n",
    "plot_band(\n",
    "    x=tf.index,\n",
    "    y1=tf[\"Vent Admits 25%\"],\n",
    "    ym=tf[\"Vent Admits Median\"],\n",
    "    y2=tf[\"Vent Admits 75%\"],\n",
    "    fill_kws=fill_kws,\n",
    "    line_kws=line_kws,\n",
    "    ax=ax,\n",
    "    zorder=20,\n",
    ")\n",
    "\n",
    "\n",
    "fig.suptitle(\n",
    "    \"General PDF vs normal PDF @ 50% C.I.\", y=1.02, fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "fig.autofmt_xdate()\n",
    "fig.tight_layout()\n",
    "\n",
    "despine()\n",
    "show_plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit)\n",
    "\n",
    "# Convert names back to original\n",
    "name_map = {\n",
    "    \"L\": \"logistic_L\",\n",
    "    \"x0\": \"logistic_x0\",\n",
    "    \"k\": \"logistic_k\",\n",
    "    \"hospital_probability\": \"hosp_prop\",\n",
    "    \"hospital_length_of_stay\": \"hosp_LOS\",\n",
    "    \"icu_probability\": \"ICU_prop\",\n",
    "    \"icu_length_of_stay\": \"ICU_LOS\",\n",
    "    \"vent_probability\": \"vent_prop\",\n",
    "    \"vent_length_of_stay\": \"vent_LOS\",\n",
    "}\n",
    "\n",
    "new_posterior = {name_map.get(key, key): val for key, val in fit.p.items()}\n",
    "new_posterior[\"logistic_x0\"] -= OFFSET\n",
    "new_prior = {name_map.get(key, key): val for key, val in pp.items()}\n",
    "\n",
    "# Create comparison frame\n",
    "comparison = DataFrame(\n",
    "    [new_prior, new_posterior, POSTERIORS],\n",
    "    index=[\"Priors\", \"PDF from normal approx\", \"PDF from general dists\",],\n",
    ").T  # .dropna()\n",
    "\n",
    "# Compute difference in standard deviations\n",
    "comparison[\"diff\"] = (\n",
    "    comparison[\"PDF from normal approx\"] - comparison[\"PDF from general dists\"]\n",
    ").dropna()\n",
    "comparison[\"z\"] = comparison[\"diff\"].apply(lambda x: abs(x.mean) / x.sdev)\n",
    "\n",
    "# Present\n",
    "comparison.sort_values(\"z\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the `hosp_prop`, fitted parameters seem to agree. This might be related to optimization criteria or the estimated data uncertainty which I have not analyzed in detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chime",
   "language": "python",
   "name": "chime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}